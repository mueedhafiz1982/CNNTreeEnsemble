# -*- coding: utf-8 -*-
"""pln_pp_6Rs_BP_ImgNt.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VoKtcArqmQ160GUE-7gB4eNXjny_epPF
"""

from google.colab import drive
drive.mount('/content/drive')

img_rows, img_cols = 224, 224 #number of rows and columns to convert the images to
input_shape = (img_rows, img_cols, 3)#format to store the images (rows, columns,channels) called channels last

import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator()  
valid_datagen = ImageDataGenerator()

train_generator1 = train_datagen.flow_from_directory(
        '/content/drive/My Drive/db/ImgNet/train/',
        classes = ['bikes&ships','tractors&wagons','cats&dogs'],
        target_size=(img_rows, img_cols),batch_size=32,class_mode='categorical')

valid_generator1 = valid_datagen.flow_from_directory(
        '/content/drive/My Drive/db/ImgNet/valid/',
        classes = ['bikes&ships','tractors&wagons','cats&dogs'],
        target_size=(img_rows, img_cols),batch_size=32,class_mode='categorical')

train_generator21 = train_datagen.flow_from_directory(
        '/content/drive/My Drive/db/ImgNet/train/',
        classes = ['bikes','ships'],
        target_size=(img_rows, img_cols),batch_size=32,class_mode='binary')

valid_generator21 = valid_datagen.flow_from_directory(
        '/content/drive/My Drive/db/ImgNet/valid/',
        classes = ['bikes','ships'], 
        target_size=(img_rows, img_cols),batch_size=32,class_mode='binary')

train_generator22 = train_datagen.flow_from_directory(
        '/content/drive/My Drive/db/ImgNet/train/',
        classes = ['tractors','wagons'],
        target_size=(img_rows, img_cols),batch_size=32,class_mode='binary')

valid_generator22 = valid_datagen.flow_from_directory(
        '/content/drive/My Drive/db/ImgNet/valid/',
        classes = ['tractors','wagons'],
        target_size=(img_rows, img_cols),batch_size=32,class_mode='binary')

train_generator23 = train_datagen.flow_from_directory(
        '/content/drive/My Drive/db/ImgNet/train/',
        classes = ['cats','dogs'],
        target_size=(img_rows, img_cols),batch_size=16,class_mode='binary')

valid_generator23 = valid_datagen.flow_from_directory(
        '/content/drive/My Drive/db/ImgNet/valid/',
        classes = ['cats','dogs'],
        target_size=(img_rows, img_cols),batch_size=16,class_mode='binary')


base_model1 = tf.keras.applications.ResNet50(weights='imagenet', include_top = False)
base_model21 = tf.keras.applications.ResNet50(weights='imagenet', include_top = False)
base_model22 = tf.keras.applications.ResNet50(weights='imagenet', include_top = False)
base_model23 = tf.keras.applications.ResNet50(weights='imagenet', include_top = False)

for layer in base_model1.layers:   layer.trainable = False
for layer in base_model21.layers:   layer.trainable = False
for layer in base_model22.layers:   layer.trainable = False
for layer in base_model23.layers:   layer.trainable = False

x = base_model1.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(512, activation='relu')(x)
preds = tf.keras.layers.Dense(3, activation ='softmax')(x)
model1 = tf.keras.models.Model(inputs=base_model1.input, outputs=preds)

x = base_model21.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(512, activation='relu')(x)
preds = tf.keras.layers.Dense(1, activation ='sigmoid')(x)
model21 = tf.keras.models.Model(inputs=base_model21.input, outputs=preds)


x = base_model22.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(512, activation='relu')(x)
preds = tf.keras.layers.Dense(1, activation ='sigmoid')(x)
model22 = tf.keras.models.Model(inputs=base_model22.input, outputs=preds)

x = base_model23.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(512, activation='relu')(x)
preds = tf.keras.layers.Dense(1, activation ='sigmoid')(x)
model23 = tf.keras.models.Model(inputs=base_model23.input, outputs=preds)

model1.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])
model21.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])
model22.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])
model23.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])

cb1= tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto',
    baseline=None, restore_best_weights=True
)

cb2= tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto',
    baseline=None, restore_best_weights=True
)

cb3= tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto',
    baseline=None, restore_best_weights=True
)

cb4= tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto',
    baseline=None, restore_best_weights=True
)


history = model1.fit(
      train_generator1,
      steps_per_epoch=train_generator1.n//train_generator1.batch_size,
      epochs=25,
      validation_data=valid_generator1,callbacks=[cb1],
      validation_steps=25)

history = model21.fit(
      train_generator21,
      steps_per_epoch=train_generator21.n//train_generator21.batch_size,
      epochs=25,
      validation_data=valid_generator21,callbacks=[cb2],
      validation_steps=10)

history = model22.fit(
      train_generator22,
      steps_per_epoch=train_generator22.n//train_generator22.batch_size,
      epochs=25,
      validation_data=valid_generator22,callbacks=[cb3],
      validation_steps=10)

history = model23.fit(
      train_generator23,
      steps_per_epoch=train_generator23.n//train_generator23.batch_size,
      epochs=25,
      validation_data=valid_generator23,callbacks=[cb4],
      validation_steps=10)

model1.save ( '/content/drive/My Drive/db/6C/Bipartite_Adam_pln_pp/model1/' )
model21.save( '/content/drive/My Drive/db/6C/Bipartite_Adam_pln_pp/model21/')
model22.save( '/content/drive/My Drive/db/6C/Bipartite_Adam_pln_pp/model22/')
model23.save( '/content/drive/My Drive/db/6C/Bipartite_Adam_pln_pp/model23/')

"""
import tensorflow as tf
model1 =tf.keras.models.load_model('/content/drive/My Drive/db/6C/Bipartite_Adam_pln_pp/model1/' )
model21=tf.keras.models.load_model('/content/drive/My Drive/db/6C/Bipartite_Adam_pln_pp/model21/')
model22=tf.keras.models.load_model('/content/drive/My Drive/db/6C/Bipartite_Adam_pln_pp/model22/')
model23=tf.keras.models.load_model('/content/drive/My Drive/db/6C/Bipartite_Adam_pln_pp/model23/')
"""

import numpy as np
from google.colab import files
from keras.preprocessing import image
import cv2
import os
import glob

ct_cat=0;ct_dog=0;ct_bike=0; ct_ship=0; ct_tractor=0; ct_wagon=0;

img_dir = '/content/drive/My Drive/db/ImgNet/test/bikes/'
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
for f1 in files:
  img = image.load_img(f1, target_size=(324, 324))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  classesb1 = model1.predict(images, batch_size=10)
  classesb21 = model21.predict(images, batch_size=10)
  #classesb22 = model22.predict(images, batch_size=10)
  #print('bikes:',classesb1[0][0],classesb21[0])
  if((classesb1[0][0] > .5) and (classesb21[0] < .5)):    ct_bike=ct_bike+1

print('./')
os.chdir('/content/')
import os

img_dir = '/content/drive/My Drive/db/ImgNet/test/ships/' # Enter Directory of all images.
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
for f1 in files:
  img = image.load_img(f1, target_size=(324, 324))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  classess1 = model1.predict(images, batch_size=10)
  classess21 = model21.predict(images, batch_size=10)
  #classess22 = model22.predict(images, batch_size=10)
  #print('ships:',classess1[0][0],classess21[0])
  if((classess1[0][0] > .5) and (classess21[0] > .5)):    ct_ship=ct_ship+1

print('./')
os.chdir('/content/')
import os
img_dir = '/content/drive/My Drive/db/ImgNet/test/tractors/' # Enter Directory of all images.
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
for f1 in files:
  img = image.load_img(f1, target_size=(324, 324))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  classest1 = model1.predict(images, batch_size=10)
  #classest21 = model21.predict(images, batch_size=10)
  classest22 = model22.predict(images, batch_size=10)
  #print('tracs:',classest1[0][1],classest22[0])
  if((classest1[0][1] > .5) and (classest22[0] < .5)):    ct_tractor=ct_tractor+1

print('./')
os.chdir('/content/')
import os
img_dir = '/content/drive/My Drive/db/ImgNet/test/wagons/' # Enter Directory of all images.
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
for f1 in files:
  img = image.load_img(f1, target_size=(324, 324))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  classesw1 = model1.predict(images, batch_size=10)
  #classesw21 = model21.predict(images, batch_size=10)
  classesw22 = model22.predict(images, batch_size=10)
  #print('wagons:',classesw1[0][1],classesw22[0])
  if((classesw1[0][1] > .5) and (classesw22[0] > .5)):    ct_wagon=ct_wagon+1

print('./')
os.chdir('/content/')
import os
img_dir = '/content/drive/My Drive/db/ImgNet/test/cats/' # Enter Directory of all images.
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
for f1 in files:
  img = image.load_img(f1, target_size=(324, 324))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  classesw1 = model1.predict(images, batch_size=10)
  #classesw21 = model21.predict(images, batch_size=10)
  classesw23 = model23.predict(images, batch_size=10)
  #print('cats:',classesw1[0][2],classesw23[0])
  if((classesw1[0][2] > .5) and (classesw23[0] < .5)):    ct_cat=ct_cat+1

print('./')
os.chdir('/content/')
import os
img_dir = '/content/drive/My Drive/db/ImgNet/test/dogs/' # Enter Directory of all images.
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
for f1 in files:
  img = image.load_img(f1, target_size=(324, 324))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  classesw1 = model1.predict(images, batch_size=10)
  #classesw21 = model21.predict(images, batch_size=10)
  classesw23 = model23.predict(images, batch_size=10)
  #print('dogs:',classesw1[0][2],classesw23[0])
  if((classesw1[0][2] > .5) and (classesw23[0] > .5)):    ct_dog=ct_dog+1

ct_total=ct_bike+ct_ship+ct_tractor+ct_wagon+ct_cat+ct_dog

print('Total = ',ct_total)
print('Breakup = ',ct_bike,ct_ship,ct_tractor,ct_wagon,ct_cat,ct_dog)  
print('accuracy=',ct_total/1022)